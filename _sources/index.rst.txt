
Natural Language Processing
===========================

**CSCI-GA 2590, New York University, Fall 2021**

Logistics
---------

-  Lectures: Wed 5:10pm-7pm EST (Rm 109, WWH)
-  Instructor: `He He <https://hhexiy.github.io>`__
-  TAs:

   -  `Udit Arora <https://uditarora.com>`__ (lead TA)
   -  Hyejin Kim
   -  Abed Qaddoumi
   -  Wenqian Ye

-  Office hours:

   -  He He: Thur 4-5pm EST (Rm 605, CDS)
   -  Udit Arora: TBD
   -  Hyejin Kim: TBD
   -  Abed Qaddoumi: TBD
   -  Wenqian Ye: TBD

-  Calender:
   `subscribe <https://calendar.google.com/calendar/u/3?cid=Y19jdmFnYmJhZWxlZHE4dTV2bDc0MGIwdGhzMEBncm91cC5jYWxlbmRhci5nb29nbGUuY29t>`__
   to get up-to-date times on lectures/office hours/due dates/etc.

Accessibility
-------------

We try to make all of the course material accessible. If you need
additional accomadation, please send us an email. Please let us know in
advance any accomadation needed for assignments and the midterm.

Course information
------------------

How can we teach machines to understand language so that they can answer
our queries, extract information from textual data, or even have a
conversation with us? The primary goal of this course is to provide
students with the principles and tools needed to solve a variety of NLP
problems. We will focus on data-driven methods, including
classification, sequence labeling, structured prediction, unsupervised
learning, and deep learning. Specific applications include text
classification, constituent parsing, semantic parsing, and generation.

Prerequisites
~~~~~~~~~~~~~

Students are expected to have solid mathematic background and
programming skills.

-  Probability, statistics, linear algebra (DS-GA.1002, MATH-UA.140,
   MATH-UA.235)
-  Algorithms and data structure (CSCI-UA.102)
-  Basic knowlege in machine learning (DS-GA.1003, CSCI-UA.0473) will be
   helpful

Resources
~~~~~~~~~

**Textbook:** There is no required textbook. Course notes/slides should
be sufficient. Some lectures will be based on the following books
(available freely online):

-  `Dan Jurafsky and James H. Martin. Speech and Language
   Processing. <https://web.stanford.edu/~jurafsky/slp3/>`__ A classic
   textbook covering both traditional and modern approaches to NLP.
-  `Jacob Eisenstein. Introduction to Natural Language
   Processing. <https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf>`__
   A comprehensive reference with additional coverage on relevant topics
   in linguistics and slightly more advanced topics in machine learning.
-  `Yoav Goldberg. Neural Network Methods for Natural Language
   Processing. <https://u.cs.biu.ac.il/~yogo/nnlp.pdf>`__ Covers neural
   network models for NLP.
-  `Aston Zhang, Zack C. Lipton, Mu Li, and Alex J. Smola. Dive into
   Deep Learning. <https://d2l.ai/index.html>`__ Covers many topics in
   neural networks and features numerous hands-on examples. We will use
   some examples from this book.

In the lecture notes, we will use JM, E, G, D2L to refer to the above
books respectively.

**Background**: Here are some useful materials if you want to review the
background knowledge.

-  Probability and optimization in the appendix of Eisensteinâ€™s book.
-  `Notes <https://cims.nyu.edu/~cfgranda/pages/DSGA1002_fall15/notes.html>`__
   from DS-GA.1002 (Probability and Statistics for Data Science).
-  Introductory machine learning material from
   `DS-GA.1002 <https://github.com/briandalessandro/DataScienceCourse/tree/master/ipython/Lectures>`__.

.. toctree::
   :maxdepth: 2
   :hidden:

   schedule
   coursework
   notes/index
